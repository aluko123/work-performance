# System Architecture

**Last Updated:** 2025-11-03  
**Status:** Production-ready  
**Stack:** FastAPI + Postgres + pgvector + OpenAI SDK

---

## ğŸ—ï¸ Current Architecture

### Database Layer
- **Postgres 16** with **pgvector** extension
- Single database for all data (analyses, utterances, embeddings)
- Fast semantic search via vector similarity (`<=>` operator)
- Alembic migrations for schema management

### Backend (FastAPI)
```
backend/
â”œâ”€â”€ main.py              # API endpoints, startup logic
â”œâ”€â”€ agent.py             # Conversational agent with tool calling
â”œâ”€â”€ tools.py             # Tool implementations (search, stats, charts)
â”œâ”€â”€ embeddings.py        # OpenAI embedding generation
â”œâ”€â”€ metadata.py          # Redis-backed metadata cache
â”œâ”€â”€ database.py          # DB connection & session management
â”œâ”€â”€ db_models.py         # SQLAlchemy ORM models
â”œâ”€â”€ models.py            # Pydantic API models
â”œâ”€â”€ worker.py            # ARQ background worker
â”œâ”€â”€ document_extractor.py # File upload processing
â”œâ”€â”€ parsing.py           # Text extraction
â”œâ”€â”€ services.py          # Business logic utilities
â”œâ”€â”€ metrics.py           # Metric calculations
â”œâ”€â”€ utils.py             # Helper functions
â”œâ”€â”€ sanitization.py      # Input validation
â””â”€â”€ config/              # Configuration (chart metrics, etc.)
```

### Frontend (React + TypeScript)
```
frontend-v2/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/      # UI components (AnalysisCard, ChatInterface)
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts       # API client
â”‚   â”‚   â””â”€â”€ types.ts     # TypeScript types
â”‚   â””â”€â”€ App.tsx          # Main app
â””â”€â”€ Dockerfile           # Nginx-based production build
```

### Data Flow

```
1. Upload Flow:
   User uploads file â†’ /analyze_text
   â†’ ARQ worker processes async
   â†’ BERT inference + parsing
   â†’ Save to Postgres
   â†’ Generate embeddings (background)

2. Chat Flow:
   User asks question â†’ /api/chat
   â†’ Agent (agent.py) with OpenAI SDK
   â†’ Calls tools (tools.py):
      - search_utterances (pgvector semantic search)
      - get_metric_stats (aggregation queries)
      - generate_chart (matplotlib)
   â†’ Streams response with charts + citations
   â†’ Saves conversation to Redis

3. Chart Generation (auto-enforced):
   Comparison query detected
   â†’ get_metric_stats called for N speakers
   â†’ System auto-injects generate_chart if LLM forgets
   â†’ Returns base64 chart image
```

---

## ğŸ“Š Key Components

### 1. Conversational Agent (`agent.py`)
- OpenAI native SDK with streaming
- Tool calling with automatic chart enforcement
- Redis conversation history
- Max 3 iterations to prevent loops

### 2. Tools System (`tools.py`)
- `list_speakers` - Get available speakers
- `list_metrics` - Get available metrics
- `search_utterances` - Semantic search via pgvector
- `get_metric_stats` - Aggregation queries
- `compare_periods` - Time-based comparisons
- `generate_chart` - Bar/line chart generation

### 3. Embeddings (`embeddings.py`)
- OpenAI `text-embedding-3-small` (1536 dimensions)
- Batch generation with rate limiting
- Stored in Postgres vector column
- IVFFlat index for fast similarity search

### 4. Background Worker (`worker.py`)
- ARQ (async Redis queue)
- Handles long-running inference tasks
- Startup indexing for new utterances
- Processes files asynchronously

---

## ğŸ—„ï¸ Database Schema

### Tables
```sql
analyses
â”œâ”€â”€ id (PK)
â”œâ”€â”€ source_filename
â””â”€â”€ created_at

utterances
â”œâ”€â”€ id (PK)
â”œâ”€â”€ analysis_id (FK â†’ analyses.id)
â”œâ”€â”€ date, timestamp, speaker
â”œâ”€â”€ text
â”œâ”€â”€ predictions (JSON)      -- BERT scores
â”œâ”€â”€ aggregated_scores (JSON) -- Aggregated metrics
â”œâ”€â”€ sa_labels (JSON)        -- Situation awareness labels
â”œâ”€â”€ is_indexed (BOOLEAN)    -- Embedding status
â””â”€â”€ embedding (vector(1536)) -- Semantic search vector

Indexes:
- idx_utterances_embedding (IVFFlat for vector similarity)
- idx_utterance_date, idx_utterance_speaker (query optimization)
```

---

## ğŸ”§ Infrastructure

### Docker Services
```yaml
postgres:    # Database (pgvector/pgvector:pg16)
migrate:     # Alembic migrations (runs on startup)
backend:     # FastAPI app (port 8000)
frontend:    # React app via Nginx (port 8001)
redis:       # Conversation cache + ARQ queue
arq_worker:  # Background task processor
```

### Environment Variables
```bash
DATABASE_URL               # Postgres connection
OPENAI_API_KEY            # OpenAI API access
REDIS_URL                 # Redis connection
MODEL_PATH                # BERT model path
SA_MODEL_PATH             # Situation awareness model
INFER_BATCH_SIZE=32       # Inference batch size
CORS_ORIGINS              # Allowed frontend origins
```

---

## ğŸ“¦ Dependencies (Simplified)

**Core:**
- fastapi, uvicorn - Web framework
- sqlalchemy, psycopg2-binary, pgvector - Database
- openai - LLM & embeddings
- redis, arq - Caching & background jobs
- alembic - DB migrations

**ML/Processing:**
- torch, transformers - BERT inference
- scikit-learn - ML utilities
- pandas, numpy - Data manipulation

**Document Processing:**
- unstructured[pdf,xlsx] - File parsing
- chunkr_ai - Text chunking

**Removed (Nov 2025):**
- ~~langchain, langchain-community, langchain-openai, langchain-core~~
- ~~langgraph~~ (complex orchestration, replaced with simple tool calling)
- ~~chromadb~~ (replaced with pgvector)

---

## ğŸš€ Performance Characteristics

**Semantic Search:**
- ~10-20ms for top-K queries (pgvector + IVFFlat index)
- Supports 2K+ utterances with room to scale to 100K+

**Inference:**
- Batch size: 32 (configurable via `INFER_BATCH_SIZE`)
- ~50-100 utterances/min on CPU

**Embedding Generation:**
- ~50-100 embeddings/min (OpenAI rate limits)
- Background processing doesn't block uploads

**Chat Response:**
- <2s for simple queries
- 3-5s for complex queries with multiple tool calls
- Streaming tokens appear within 500ms

---

## ğŸ¯ API Endpoints

### Active Endpoints
```
POST /analyze_text        # Upload & analyze document
GET  /analyses/           # List all analyses (paginated)
GET  /analyses/{id}       # Get specific analysis
GET  /api/trends          # Time-series data
POST /api/chat            # Conversational agent (primary)
```

### Removed Endpoints
```
POST /api/get_insights    # REMOVED (use /api/chat)
```

---

## ğŸ” Security Notes

- All secrets in `.env` (never committed)
- CORS properly configured
- Database credentials: non-production defaults (change in prod)
- No exposed admin interfaces
- Input sanitization on all endpoints

---

## ğŸ“ˆ Recent Improvements (Nov 2025)

1. **SQLite â†’ Postgres migration**
   - Production-ready database
   - Better concurrency & reliability
   - Transactional integrity

2. **ChromaDB â†’ pgvector migration**
   - Single database (simpler ops)
   - Faster queries
   - Better scalability

3. **LangChain â†’ OpenAI native SDK**
   - Removed ~1,100 lines of complex code
   - Simpler, more maintainable
   - Better streaming support
   - Automatic chart generation enforcement

4. **Codebase cleanup**
   - Removed 468 MB of unused data
   - Removed 6 deprecated dependencies
   - Cleaner file structure
   - Better documentation

---

## ğŸ§ª Testing

**Run tests:**
```bash
docker compose run --rm backend pytest backend/tests/
```

**Key test files:**
- `test_agent.py` - Agent & tool calling
- `test_services.py` - Business logic
- `test_api.py` - API endpoints
- `test_prompts.py` - Prompt templates

---

## ğŸ“š Documentation

- [AGENTS.md](AGENTS.md) - Dev guidelines & commands
- [README.md](README.md) - Project overview
- [POSTGRES_MIGRATION.md](POSTGRES_MIGRATION.md) - Migration guide
- [BACKLOG.md](BACKLOG.md) - Future features
- [DEPRECATED_FILES.md](implementation/DEPRECATED_FILES.md) - Cleanup history
- [PROFILING.md](PROFILING.md) - Performance profiling

---

## ğŸ”„ Migration Status

| Component | From | To | Status |
|-----------|------|----|----|
| Database | SQLite | Postgres+pgvector | âœ… Complete |
| Vector Store | ChromaDB | pgvector | âœ… Complete |
| Agent Framework | LangGraph | OpenAI SDK | âœ… Complete |
| Embeddings | ChromaDB index | Postgres column | âœ… Complete |
| Frontend | frontend/ | frontend-v2/ | âœ… Complete |

---

## ğŸ¨ Code Quality Metrics

**Backend:**
- 27 Python files
- ~4,500 total lines (down from ~5,600)
- Single responsibility principle
- Type hints throughout
- Comprehensive error handling

**Architecture Score:**
- âœ… Single database (no data fragmentation)
- âœ… Async everywhere (better concurrency)
- âœ… Streaming responses (better UX)
- âœ… Background processing (non-blocking uploads)
- âœ… Automatic failsafes (chart enforcement)
- âœ… Production-ready stack (Postgres, Redis, Docker)
